---
title: "Computational Musicology"
vauthor: "Hannah Min"
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
---

```{r setup, include=FALSE}
library(flexdashboard)
```


```{R}
library(tidyverse)
library(compmus)
library(spotifyr)
source('spotify.R')
library(knitr)
library(ggplot2)
library(plotly)
library(shiny)
require(gridExtra)
```


### Introduction



image

***

**Introduction**

Hip hop is said to be invented by the Jamaican Kool DJ Herc in 1973 in New York's Bronx (Blanchard, 1999). He used an new turntable technique to stretch a song's drum break (Blanchard, 1999). Rap, the lyrics of the music came up when DJ's were playing at a hip hop event and people started to comment on the abilities of the DJ (Blanchard, 1999). Hip hop as both a musical genre and a culture reached different parts of the world. In the Netherlands this resulted in the genre Nederhop (Koreman, 2014). It was adapted to the Dutch market, especially by using the Dutch language. Nederhop is highly influenced by american hip hop. Both dutch and american hip hop music are embedded in a different culture, which makes it interesting to research how they differ from each other. In this study the Spotify Developer toolkit is used to analyse both musical styles, based on a corpus. This resulted in the following research question: *How does Dutch hip hop compare to US hip hop in terms of their Spotify features?*




References:

Blanchard, B. (1999). The social significance of rap & hip-hop culture. Journal of Poverty & Prejudice, Spring.

Koreman, R. (2014). Legitimating Local Music: Volksmuziek, Hip-Hop/Rap and Dance Music in Dutch Elite Newspapers. Cultural Sociology, 8(4), 501-519.

### Corpus

**Corpus**
```{r}
hiphopNL_features <- get_playlist_audio_features("1110731694", "5Ady4U59sfaqcvwEoepX0L")
hiphopNL_features$playlist_name <- "Hip hop NL"

hiphopUS_features <- get_playlist_audio_features("jonathangutsche", "37HfKsPNsDABlvJmik64oa")

all_music <- rbind(hiphopNL_features, hiphopUS_features)

num_hiphopNL <- hiphopNL_features[, c("danceability", "energy", "loudness", "speechiness", "acousticness", "instrumentalness", "liveness", "valence", "tempo")]

num_hiphopUS <- hiphopUS_features[, c("danceability", "energy", "loudness", "speechiness", "acousticness", "instrumentalness", "liveness", "valence", "tempo")]

```

|                |URI's                                                       | Songs|
|---------:      |---------:                                                  |---------:|
|Dutch hip hop   |spotify:user:1110731694:playlist:5Ady4U59sfaqcvwEoepX0L     | 789|
|American hip hop|spotify:user:jonathangutsche:playlist:37HfKsPNsDABlvJmik64oa| 449|

(still looking for anothe suitable US hip hop playlist to have an equal amount of data for both styles)


**First look at the data**

These are the means and standard deviations for the numeric features.

```{r}
mean_NL <- colMeans(num_hiphopNL)
sd_NL <- sapply(num_hiphopNL, sd, na.rm = TRUE)

mean_US <- colMeans(num_hiphopUS)
sd_US <- sapply(num_hiphopUS, sd, na.rm = TRUE)

table <- data.frame(mean_NL, sd_NL, mean_US, sd_US)
knitr::kable(table)

```

The values for American and Dutch hip hop are very much alike. It can be noticed that the standard deviations for the Dutch hip hop are smaller.

### Energy Valence Diagram

```{r}
e_v <- ggplot(all_music, aes(x=valence, y=energy, color=playlist_name, label = artist_name, label2 = track_name)) + geom_point(shape = 21)
ggplotly(e_v)
```

***
comment

### Cepstrograms

```{r}
# Drake take care
take_care <- 
    get_tidy_audio_analysis('124NFj84ppZ5pAxTuVQYCQ') %>% 
    compmus_align(bars, segments) %>% 
    select(bars) %>% unnest(bars) %>% 
    mutate(
        pitches = 
            map(segments, 
                compmus_summarise, pitches, 
                method = 'rms', norm = 'euclidean')) %>% 
    mutate(
        timbre = 
            map(segments, 
                compmus_summarise, timbre, 
                method = 'mean'))
cep1 <- take_care %>% 
    compmus_gather_timbre %>% 
    ggplot(
        aes(
            x = start + duration / 2, 
            width = duration, 
            y = basis, 
            fill = value)) + 
    geom_tile() +
    labs(x = 'Time (s)', y = NULL, fill = 'Magnitude') +
    scale_fill_viridis_c(option = 'E') +
    theme_classic()


# Slapend rijk
slapend_rijk <-
    get_tidy_audio_analysis('3PiDnD8RhPrlmzMpAgF9xK') %>%
    compmus_align(bars, segments) %>%
    select(bars) %>% unnest(bars) %>%
    mutate(
        pitches =
            map(segments,
                compmus_summarise, pitches,
                method = 'rms', norm = 'euclidean')) %>%
    mutate(
        timbre =
            map(segments,
                compmus_summarise, timbre,
                method = 'mean'))

cep2 <- slapend_rijk %>%
    compmus_gather_timbre %>%
    ggplot(
        aes(
            x = start + duration / 2,
            width = duration,
            y = basis,
            fill = value)) +
    geom_tile() +
    labs(x = 'Time (s)', y = NULL, fill = 'Magnitude') +
    scale_fill_viridis_c(option = 'E') +
    theme_classic()
```

```{R}
grid.arrange(cep1, cep2, ncol=2, heights=c(1,1), top = "Cepstogram Take care vs. Slapend rijk")

```


***
On the left:

Song: Take care

Artist(s): Drake, Rihanna

On the right:

Song: Slapend Rijk

Artist(s): Boef, Sevn Alias

### Self-similarity matrices
```{r}
sim1 <- take_care %>%
    compmus_self_similarity(timbre, 'cosine') %>%
    ggplot(
        aes(
            x = xstart + xduration / 2,
            width = xduration,
            y = ystart + yduration / 2,
            height = yduration,
            fill = d)) +
    geom_tile() +
    coord_fixed() +
    scale_fill_viridis_c(option = 'E', guide = 'none') +
    theme_classic() +
    labs(x = '', y = '')

sim2 <- slapend_rijk %>%
    compmus_self_similarity(timbre, 'cosine') %>%
    ggplot(
        aes(
            x = xstart + xduration / 2,
            width = xduration,
            y = ystart + yduration / 2,
            height = yduration,
            fill = d)) +
    geom_tile() +
    coord_fixed() +
    scale_fill_viridis_c(option = 'E', guide = 'none') +
    theme_classic() +
    labs(x = '', y = '')

grid.arrange(sim1, sim2, ncol=2, top = "Self-similarity matrixes Take care vs. Slapend rijk")

```

***
On the left:

Song: Take care

Artist(s): Drake, Rihanna

On the right:

Song: Slapend Rijk

Artist(s): Boef, Sevn Alias

### Keygrams


```{r}
circshift <- function(v, n) {if (n == 0) v else c(tail(v, n), head(v, -n))}
                                    
    # C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B 
major_chord <- 
    c(1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <- 
    c(1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <- 
    c(1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <- 
    c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
    c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
    tribble(
        ~name  , ~template,
        'Gb:7'  , circshift(seventh_chord,  6),
        'Gb:maj', circshift(major_chord,    6),
        'Bb:min', circshift(minor_chord,   10),
        'Db:maj', circshift(major_chord,    1),
        'F:min' , circshift(minor_chord,    5),
        'Ab:7'  , circshift(seventh_chord,  8),
        'Ab:maj', circshift(major_chord,    8),
        'C:min' , circshift(minor_chord,    0),
        'Eb:7'  , circshift(seventh_chord,  3),
        'Eb:maj', circshift(major_chord,    3),
        'G:min' , circshift(minor_chord,    7),
        'Bb:7'  , circshift(seventh_chord, 10),
        'Bb:maj', circshift(major_chord,   10),
        'D:min' , circshift(minor_chord,    2),
        'F:7'   , circshift(seventh_chord,  5),
        'F:maj' , circshift(major_chord,    5),
        'A:min' , circshift(minor_chord,    9),
        'C:7'   , circshift(seventh_chord,  0),
        'C:maj' , circshift(major_chord,    0),
        'E:min' , circshift(minor_chord,    4),
        'G:7'   , circshift(seventh_chord,  7),
        'G:maj' , circshift(major_chord,    7),
        'B:min' , circshift(minor_chord,   11),
        'D:7'   , circshift(seventh_chord,  2),
        'D:maj' , circshift(major_chord,    2),
        'F#:min', circshift(minor_chord,    6),
        'A:7'   , circshift(seventh_chord,  9),
        'A:maj' , circshift(major_chord,    9),
        'C#:min', circshift(minor_chord,    1),
        'E:7'   , circshift(seventh_chord,  4),
        'E:maj' , circshift(major_chord,    4),
        'G#:min', circshift(minor_chord,    8),
        'B:7'   , circshift(seventh_chord, 11),
        'B:maj' , circshift(major_chord,   11),
        'D#:min', circshift(minor_chord,    3),
)

key_templates <-
    tribble(
        ~name    , ~template,
        'Gb:maj', circshift(major_key,  6),
        'Bb:min', circshift(minor_key, 10),
        'Db:maj', circshift(major_key,  1),
        'F:min' , circshift(minor_key,  5),
        'Ab:maj', circshift(major_key,  8),
        'C:min' , circshift(minor_key,  0),
        'Eb:maj', circshift(major_key,  3),
        'G:min' , circshift(minor_key,  7),
        'Bb:maj', circshift(major_key, 10),
        'D:min' , circshift(minor_key,  2),
        'F:maj' , circshift(major_key,  5),
        'A:min' , circshift(minor_key,  9),
        'C:maj' , circshift(major_key,  0),
        'E:min' , circshift(minor_key,  4),
        'G:maj' , circshift(major_key,  7),
        'B:min' , circshift(minor_key, 11),
        'D:maj' , circshift(major_key,  2),
        'F#:min', circshift(minor_key,  6),
        'A:maj' , circshift(major_key,  9),
        'C#:min', circshift(minor_key,  1),
        'E:maj' , circshift(major_key,  4),
        'G#:min', circshift(minor_key,  8),
        'B:maj' , circshift(major_key, 11),
        'D#:min', circshift(minor_key,  3))
```


```{r}
wow <-
    get_tidy_audio_analysis('6716bTJI7qiHJFFSR0Ethe') %>%
    compmus_align(sections, segments) %>%
    select(sections) %>% unnest(sections) %>%
    mutate(
        pitches =
            map(segments,
                compmus_summarise, pitches,
                method = 'mean', norm = 'manhattan'))

hivm <-
    get_tidy_audio_analysis('6MWtB6iiXyIwun0YzU6DFP') %>%
    compmus_align(sections, segments) %>%
    select(sections) %>% unnest(sections) %>%
    mutate(
        pitches =
            map(segments,
                compmus_summarise, pitches,
                method = 'mean', norm = 'manhattan'))
```

```{r}
key_wow <- wow %>%
    compmus_match_pitch_template(key_templates, 'euclidean', 'manhattan') %>%
    ggplot(
        aes(x = start + duration / 2, width = duration, y = name, fill = d)) +
    geom_tile() +
    scale_fill_viridis_c(option = 'E', guide = 'none') +
    theme_minimal() +
    labs(x = 'Time (s)', y = '')

key_hivm <- hivm %>%
    compmus_match_pitch_template(key_templates, 'euclidean', 'manhattan') %>%
    ggplot(
        aes(x = start + duration / 2, width = duration, y = name, fill = d)) +
    geom_tile() +
    scale_fill_viridis_c(option = 'E', guide = 'none') +
    theme_minimal() +
    labs(x = 'Time (s)', y = '')

grid.arrange(key_wow, key_hivm, ncol=2, top = "Keygram Wow vs. Hij is van mij")
```

***

On the left:

Song: Wow

Artist(s): Post Malone

On the right:

Song: Hij Is Van Mij (feat. Bizzey)

Artist(s): Kriss Kross Amsterdam, Maan, Tabitha